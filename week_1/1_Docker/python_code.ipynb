{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python analytics of NY taxi data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe\n",
    "df = pd.read_csv(\"yellow_tripdata_2021-01.csv\", nrows=100)\n",
    "df[\"tpep_dropoff_datetime\"] = pd.to_datetime(df[\"tpep_dropoff_datetime\"])\n",
    "df[\"tpep_pickup_datetime\"] = pd.to_datetime(df[\"tpep_pickup_datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas uses SQLAlchemy, need to install with pip\n",
    "#pip install sqlalchemy\n",
    "#pip install psycopg2\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas io library can generate SQL for DDL commands:\n",
    "print(pd.io.sql.get_schema(df, name='yellow_taxi_data', con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#over 1M rows in ny taxi data, upload data to db in batches\n",
    "df_iter = pd.read_csv('yellow_tripdata_2021-01.csv', iterator=True, chunksize=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a python iterator\n",
    "type(df_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the next function to get the next value in an iterator\n",
    "df_0 = next(df_iter)\n",
    "df_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0[\"tpep_dropoff_datetime\"] = pd.to_datetime(df_0[\"tpep_dropoff_datetime\"])\n",
    "df_0[\"tpep_pickup_datetime\"] = pd.to_datetime(df_0[\"tpep_pickup_datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# first create the table using the columns without inserting any data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_head \u001b[38;5;241m=\u001b[39m \u001b[43mdf_0\u001b[49m\u001b[38;5;241m.\u001b[39mhead(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m df_head\u001b[38;5;241m.\u001b[39mto_sql(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myellow_taxi_data\u001b[39m\u001b[38;5;124m'\u001b[39m, con\u001b[38;5;241m=\u001b[39mengine, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_0' is not defined"
     ]
    }
   ],
   "source": [
    "# first create the table using the columns without inserting any data\n",
    "df_head = df_0.head(n=0)\n",
    "df_head.to_sql(name='yellow_taxi_data', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check that table created in postgres in terminal**\n",
    "\n",
    "pgcli -h localhost -p 5432 -u root -d ny_taxi\n",
    "\n",
    "Check for tables:\n",
    "\\dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert first 100000 rows to table. time the command\n",
    "%time df_0.to_sql(name='yellow_taxi_data', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk in 10.015 seconds\n",
      "inserted another chunk in 9.440 seconds\n",
      "inserted another chunk in 9.089 seconds\n",
      "inserted another chunk in 9.063 seconds\n",
      "inserted another chunk in 9.233 seconds\n",
      "inserted another chunk in 8.956 seconds\n",
      "inserted another chunk in 9.172 seconds\n",
      "inserted another chunk in 8.963 seconds\n",
      "inserted another chunk in 8.857 seconds\n",
      "inserted another chunk in 8.905 seconds\n",
      "inserted another chunk in 8.844 seconds\n",
      "inserted another chunk in 8.772 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12099/2242597660.py:3: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for df in df_iter:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk in 8.858 seconds\n",
      "inserted another chunk in 5.899 seconds\n"
     ]
    }
   ],
   "source": [
    "# now insert all data\n",
    "from time import time\n",
    "for df in df_iter:\n",
    "    start_ts = time()\n",
    "    df[\"tpep_dropoff_datetime\"] = pd.to_datetime(df[\"tpep_dropoff_datetime\"])\n",
    "    df[\"tpep_pickup_datetime\"] = pd.to_datetime(df[\"tpep_pickup_datetime\"])\n",
    "\n",
    "    df.to_sql(name='yellow_taxi_data', con=engine, if_exists='append')\n",
    "    end_ts = time()\n",
    "\n",
    "    print('inserted another chunk in %.3f seconds' % (end_ts - start_ts))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
